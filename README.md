Welcome to my Neural Network Implementations repository! This project aims to provide a comprehensive understanding of popular neural network architectures by reimplementing them from their original research papers. The implementations are done in two stages: first using TensorFlow for a higher-level, efficient approach, and then from scratch using NumPy to grasp the core mathematical operations behind the networks. To demonstrate the practical utility of these neural networks, I will be applying them to real-world datasets. This not only showcases the models' capabilities but also provides a context for their use in solving tangible problems. Furthermore, I will be providing blogs on the challenges and thought-process as I implement each neural network.

Current Implementations:

1. LeNet-5 (Tensorflow only)
Paper: Gradient-Based Learning Applied to Document Recognition by Yann LeCun, LÃ©on Bottou, Yoshua Bengio, and Patrick Haffner.
http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf
